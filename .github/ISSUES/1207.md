# Unable to apply to multiple workspaces through providers

**devops-ameyer** commented *May 29, 2020*

I'm unable to add multiple providers through terragrunt. I'm attempting to declare a provider in my module for static resources that always need to be created in the correct account and declare a provider where resources will be created in their appropriate accounts.

When I attempt to apply, the resources are applied to the provider in the module not in the terragrunt.hcl.

Here is my module:
```
########################
# AWS Transfer Service #
########################
resource "aws_iam_role" "aws_transfer_role" {
  provider = aws.main
  name = format("aws-transfer-iam-role-%s-%s",var.product_name,var.env)

  assume_role_policy = data.aws_iam_policy_document.transfer_role.json
}
resource "aws_iam_role_policy" "aws_transfer_role_policy" {
  provider = aws.main
  name = format("aws-transfer-iam-role-policy-%s-%s",var.product_name,var.env)

  role= aws_iam_role.aws_transfer_role.id

  policy = data.aws_iam_policy_document.aws_sftp.json
}
resource "aws_transfer_server" "aws_transfer_service" {
  provider = aws.main
  identity_provider_type = "SERVICE_MANAGED"
  logging_role = aws_iam_role.aws_transfer_role.arn

  tags = {
    Name = format("aws-transfer-service-%s-%s",var.product_name,var.env)
    Environment = var.env
    Project = var.product_name
    Terraform = true
  }
}
resource "aws_transfer_user" "aws_transfer_users" {
  provider = aws.main
  for_each = var.transfer_users_and_keys

  server_id = aws_transfer_server.aws_transfer_service.id
  user_name = each.key
  role = aws_iam_role.aws_transfer_role.arn

  tags = {
    Name = each.key
    Project = var.product_name
    Terraform = true
  }
}
resource "aws_transfer_ssh_key" "transfer_key" {
  provider = aws.main
  for_each = var.transfer_users_and_keys

  server_id = aws_transfer_server.aws_transfer_service.id
  user_name = each.key
  body = file("${path.module}/keys/${each.value}")

  depends_on = [
    aws_transfer_user.aws_transfer_users
  ]
}
resource "aws_iam_role" "aws_sftp" {
  provider = aws.main
  name = format("aws-sftp-%s-%s",var.product_name,var.env)

  assume_role_policy = data.aws_iam_policy_document.transfer_role.json
}
resource "aws_iam_role" "logging_role" {
  provider = aws.main
  name = format("aws-sftp-logging-%s-%s",var.product_name,var.env)

  assume_role_policy = data.aws_iam_policy_document.logging_role.json
}
resource "aws_iam_role_policy" "logging_role_policy" {
  provider = aws.main
  name = format("aws-sftp-logging-policy-%s-%s",var.product_name,var.env)

  role= aws_iam_role.logging_role.id

  policy = data.aws_iam_policy_document.sftp_logging.json
}
############
# Route 53 #
############
resource "aws_route53_record" "sftp_record" {
  provider = aws.master
  zone_id = data.aws_route53_zone.facteus.zone_id
  name = format("%s-%s",var.product_name,var.env)
  type = "CNAME"
  ttl = "30"
  records = [aws_transfer_server.aws_transfer_service.endpoint]
  # alias {
  #   name = aws_transfer_server.aws_transfer_service.endpoint
  #   zone_id = data.aws_route53_zone.facteus.zone_id
  #   evaluate_target_health = false
  # }
}
resource "null_resource" "associate_custom_hostname" {
  provisioner  "local-exec" {
    command = <<EOF
    aws transfer tag-resource --arn '${aws_transfer_server.aws_transfer_service.arn}' --tags 'Key=aws:transfer:customHostname,Value=${format("%s-%s",aws_route53_record.sftp_record.name,data.aws_route53_zone.facteus.name)}' 'Key=aws:transfer:route53HostedZoneId,Value=/hostedzone/${data.aws_route53_zone.facteus.zone_id}' --profile ${var.account}
    EOF
  }
    depends_on = [aws_transfer_server.aws_transfer_service, aws_route53_record.sftp_record]
}
######
# S3 #
######
resource "aws_s3_bucket" "aws_sftp_bucket" {
  provider = aws.master
  for_each = toset(var.sftp_bucket)

  bucket = format("facteus-%s-%s-client",var.env,var.product_name)
  acl = "private"

  versioning {
      enabled = true
  }
  lifecycle_rule {
    id = "INTELLIGENT_TIERING"
    enabled = true

    prefix = "*"

    transition {
      days = 30
      storage_class = "INTELLIGENT_TIERING"
    }
    transition {
      days = 360
      storage_class = "GLACIER"
    }
    expiration {
      days = 1800
    }
  }
  server_side_encryption_configuration {
    rule {
      apply_server_side_encryption_by_default {
        kms_master_key_id = aws_kms_key.s3_key.arn
        sse_algorithm = "aws:kms"
      }
    }
  }
  tags = {
      Project = var.product_name
      Terraform = true
      Environment = var.env
  }
  force_destroy = true
}
resource "aws_s3_bucket_policy" "aws_transfer_bucket_policy" {
  provider = aws.master
  for_each = aws_s3_bucket.aws_sftp_bucket
  bucket = aws_s3_bucket.aws_sftp_bucket[each.key].id

  policy = <<Policy
{
      "Version": "2012-10-17",
      "Id": "SFTP_Policy",
      "Statement": [
        {
          "Sid": "DM_InternalAccess",
          "Effect": "Allow",
          "Principal": {
            "AWS": [
              "${aws_iam_role.aws_transfer_role.arn}"
            ]
          },
          "Action": "s3:*",
          "Resource": [
              "${aws_s3_bucket.aws_sftp_bucket[each.key].arn}",
              "${aws_s3_bucket.aws_sftp_bucket[each.key].arn}/*"
          ]
        }
      ]
}
    Policy
}
#######
# KMS #
#######
resource "aws_kms_key" "s3_key" {
  provider = aws.master
  description = "This key is used to encrypt bucket objects"
  deletion_window_in_days = 10
  enable_key_rotation = true

  tags = {
    Terraform = true
    Name = "s3_kms_key_pci"
  }
}
########
# Data #
########
#IAM
data "aws_iam_policy_document" "aws_sftp" {
  provider = aws.main
  statement {
    sid = "AllowListingOfUserFolder"
    actions = [
      "s3:ListBucket",
      "s3:GetBucketLocation"
    ]
    resources = [
        "${aws_s3_bucket.aws_sftp_bucket[var.sftp_bucket[0]].arn}",
        "${aws_s3_bucket.aws_sftp_bucket[var.sftp_bucket[0]].arn}/*"
    ]
  }
}
data "aws_iam_policy_document" "transfer_role" {
  provider = aws.main
  statement {
    sid = "AllowSFTPService"
    actions = [
      "sts:AssumeRole"
    ]
    principals {
      type = "Service"

      identifiers = [
        "transfer.amazonaws.com"
      ]
    }
  }
}
data "aws_iam_policy_document" "logging_role" {
  provider = aws.main
  statement {
    sid = "AllowSFTPService"
    actions = [
      "sts:AssumeRole"
    ]
    principals {
      type = "Service"

      identifiers = [
        "cloudwatch.amazonaws.com"
      ]
    }
  }
}
data "aws_iam_policy_document" "sftp_logging" {
  provider = aws.main
  statement {
    sid = "AllowFullAccesstoCloudWatchLogs"
    actions = [
      "logs:*",
    ]
    resources = [
      "*"
    ]
  }
}
#Route53
data "aws_route53_zone" "facteus" {
  provider = aws.master
  name         = "facteus.com."
  private_zone = false
}
############
# Provider #
############
provider "aws" {
  alias = "master"
  region = "us-east-2"
  shared_credentials_file = "/c/Users/Alex/.aws/credentials"
  profile = "arm-master"
  # assume_role {
  #   role_arn = "arn:aws:iam::669009744290:role/terragrunt-role"
  # }
}
```

And here is where I'm declaring my provider in terragrunt.hcl: 
```
remote_state {
  backend = "s3"
#   generate = {
#       path = "backend.tf"
#       if_exists = "overwrite"
#   }
  config = {
    bucket                  = "arm-terraform-state"
    key                     = "${path_relative_to_include()}/terraform.tfstate"
    region                  = "us-west-2"
    dynamodb_table          = "arm-terraform-state-lock"
    profile                 = "arm-master"

  }
  generate = {
    path = "backend.tf"
    if_exists = "overwrite_terragrunt"
  }
}
generate "provider" {
  path = "provider.tf"
  if_exists = "overwrite_terragrunt"
  contents = <<EOF
provider "aws" {
  alias                   = "main"
  region                  = "${local.aws_region}"
  profile                 = "${local.account}"
}
EOF
}
locals {
    region_vars = read_terragrunt_config(find_in_parent_folders("region.hcl"))
    account_vars = read_terragrunt_config(find_in_parent_folders("account.hcl"))
    aws_region   = local.region_vars.locals.aws_region
    account = local.account_vars.locals.aws_profile
}
```
<br />
***


**brikis98** commented *May 31, 2020*

Why declare a `provider` in the module _and_ `terragrunt.hcl`? The result will be that you have two `provider` declarations, and at that point, it's up to Terraform rules (not Terragrunt) which one gets used.
***

**devops-ameyer** commented *Jun 1, 2020*

I thought to declare the "master" provider in the module because that account should never change. Using this setup would allow users to use the module without needing to know that there is another account where things like KMS and DNS are being created.

***

**brikis98** commented *Jun 1, 2020*

Oh, I gotcha, on my first read, I didn't notice that you had aliased the provider everywhere. OK, so what makes you think the wrong provider is being used? Could you share the log output of what's happening?
***

**devops-ameyer** commented *Jun 4, 2020*

Sorry for the delay. It seems the issue may be related to terraform itself. I'm unable to use multiple providers in my module directly or in terragrunt directly.
***

**devops-ameyer** commented *Jun 4, 2020*

It seems to only run on the aws.master provider. 
***

**devops-ameyer** commented *Jun 4, 2020*

From the documentation, I'm reading. I should be able to provide providers explicitly when calling the module but I don't think Terragrunt supports this functionality?  https://www.terraform.io/docs/configuration/modules.html#passing-providers-explicitly
***

**brikis98** commented *Jun 5, 2020*

You set the providers in your Terraform code (`.tf`).
***

**devops-ameyer** commented *Jun 5, 2020*

Yeah I tried that and it was still applying everything to the master alias.
I decided to rip it all apart and deploy resources to the master account
through a separate .tf and call those created resources through outputs.

Thank you


On Fri, Jun 5, 2020 at 1:37 AM Yevgeniy Brikman <notifications@github.com>
wrote:

> You set the providers in your Terraform code (.tf).
>
> â€”
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/gruntwork-io/terragrunt/issues/1207#issuecomment-639341508>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AM4SKYXOH6ZEZHWTLFSZLU3RVCVGNANCNFSM4NONONDQ>
> .
>

***

**yorinasub17** commented *Sep 27, 2021*

Closing this as the original question has been answered. If there are any follow ups, please open a new ticket with updated context. Thanks!
***

