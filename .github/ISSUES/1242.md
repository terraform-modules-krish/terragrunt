# Addition of `s3_bucket_tags` after remote state init fails to tag bucket

**ChefAustin** commented *Jul 1, 2020*

I noticed earlier this week that there might be an issue regarding `s3_bucket_tags` and `terragrunt` evaluating changes needing to be made.

**Environment:**
- `terraform` v0.12.26
- `terragrunt` v0.23.27
- `aws-cli/1.16.291 Python/3.5.3 Linux/4.9.0-11-amd64 botocore/1.17.10`
- `TF_INPUT=0` set as ENV var

We had set up our `terragrunt.hcl` config as follows:

```
remote_state {
  backend = "s3"

  config = {
    bucket = "my-super-neat-tf-state-bucket"
    key = "${path_relative_to_include()}/terraform.tfstate"
    region         = "us-east-1"
    role_arn       = "arn:aws:iam::1234567890:role/federated/fed_SooperSecret"
    encrypt        = true
    dynamodb_table = "my-super-neat-tf-locks-dynamo"    
  }
}
```

The above configuration worked as desired and all was fine and dandy. But we then realized that adding some tags to the S3 bucket for remote state would be super rad, and modified the config to reflect:

```
remote_state {
  backend = "s3"

  config = {
    bucket = "my-super-neat-tf-state-bucket"
    key = "${path_relative_to_include()}/terraform.tfstate"
    region         = "us-east-1"
    role_arn       = "arn:aws:iam::1234567890:role/federated/fed_SooperSecret"
    encrypt        = true
    dynamodb_table = "my-super-neat-tf-locks-dynamo"

    s3_bucket_tags = {
      "MyOrg Team" = "Super Neat Team"
      "MyOrg Service" = "SuperNeatTeam-terraform"
    }

  }
}
```

We are running `terragrunt` in CI using the following call:

```
/var/some-ci-tool/application-data/some-ci-tool/terragrunt plan-all \
    --terragrunt-tfpath /var/some-ci-tool/application-data/some-ci-tool/terraform \
    --terragrunt-working-dir ./development

/var/some-ci-tool/application-data/some-ci-tool/terragrunt apply-all \
    --terragrunt-tfpath /var/some-ci-tool/application-data/some-ci-tool/terraform \
    --terragrunt-non-interactive \
    --terragrunt-working-dir ./development
```

After the above invocation, I was met with `No changes. Infrastructure is up-to-date.`. That said, it seems to me that defining `s3_bucket_tags` _after_ the `remote_state` configuration has already been applied/in in-use, then these tag additions are not respected as a change to the infrastructure (and, ultimately, are not applied to the bucket). While we did not attempt to tag the DynamoDB table using `dynamodb_table_tags` but I am guessing that this issue might also affect it, as well.

While troubleshooting this issue, I came upon Issue #608 and saw that some folks experienced a similar issue and were able to rectify it by clearing the `.terragrunt-cache` directories but I did not find any such folders in my environment. In order to get these tags applied to the bucket, I completely destroyed the infrastructure (including the S3 bucket, DynamoDB table) and rebuilt everything from scratch. After doing this, the tags were applied.

I thought of one other method for getting the tags applied (but I have not tested this theory) was to make some other arbitrary change to the infrastructure (like adding an ephemeral EC2 instance or, really, anything) so there were _certainly_ other changes that would need to be applied in order to get the infrastructure to the desired state. My thought here is that if there was a _true_ infrastructure change (and not just a, for lack of a better word, "metadata change"; i.e. the S3 bucket tags) then perhaps the newly added `s3_bucket_tags` block would have been recognized and applied. Again, I haven't tested this theory as I thought of it _after_ I had already got the tags appended to the bucket (by completely destroying and recreating everything, as I mentioned earlier).

Perhaps I was just doing something goofy or holding `terragrunt` wrong, though. ðŸ˜Ž 

Thanks!
<br />
***


**brikis98** commented *Jul 5, 2020*

I believe Terragrunt currently only applies S3 settings when initially creating the bucket. If the bucket already exists, I don't believe it updates the config. This is functionality that has grown organically, starting with _just_ creating the S3 bucket, then later adding DynamoDB, then later tags, encryption, and so on, and I don't think we took a step back to think about the update or delete use case...

I think that before we do any future improvements to the bucket / table auto creation, we should pause and take a step back, and think holistically about how this functionality should work. For example, perhaps instead of somewhat magical  auto creation of the bucket, the better approach would be:

1. Allow users to define a Terraform module somewhere that controls how their backend (e.g., S3) is configured.
1. When you run Terragrunt, it checks if the backend exists; if it doesn't, it runs  `apply` in that module. 
1. There would need to be some sort of flow for re-running `apply` in that module too, if there were updates to the module. Running `apply` in that module every single time would work, as the `apply`  would usually be a no-op, but it would also make every single Terraform operation much slower, so more thought is needed here.

Proposals / PRs / RFCs welcome :)
***

**yorinasub17** commented *Jul 6, 2020*

Also see https://github.com/gruntwork-io/terragrunt/issues/924 , which has a related discussion including past thoughts on the feature proposed and current workarounds.
***

**ChefAustin** commented *Jul 9, 2020*

> I believe Terragrunt currently only applies S3 settings when initially creating the bucket. If the bucket already exists, I don't believe it updates the config.

This mirrors the behaviors I have experienced.

> This is functionality that has grown organically, starting with just creating the S3 bucket, then later adding DynamoDB, then later tags, encryption, and so on, and I don't think we took a step back to think about the update or delete use case...

Understood. I appreciate all the "gruntwork" that Terragrunt has been able to handle for me, so I'm quite grateful that Terragrunt is able to create the S3 bucket, DynamoDB table, encrypt, et al.

> 3. There would need to be some sort of flow for re-running apply in that module too, if there were updates to the module. Running apply in that module every single time would work, as the apply would usually be a no-op, but it would also make every single Terraform operation much slower, so more thought is needed here.

Agreed on this point; in my humble opinion, ensuring idempotence on the backend resource(s) -- not only the existence of the resources, but also their associated metadata -- should assuredly be a requirement of any future changes to Terragrunt's treatment of backend configurations.

> Also see #924 , which has a related discussion including past thoughts on the feature proposed and current workarounds.

Thanks for linking to this issue; there's some good ideas being discussed over there!


I'm hoping to have time in the next few weeks to take a look at the Terragrunt source for remote state backend configurations and see if any clever solutions come to me. 
***

**jmreicha** commented *Apr 22, 2022*

Running into this one. Is there a way now to add tags to existing state buckets? I couldn't find much else other than issues relating to adding the tags when the buckets are first created.
***

**neilhwatson** commented *May 31, 2023*

The docs state that the bucket is updated if the remote_state block changes, but as the ticket creator states new tags are not added.

> Additionally, for the S3 backend only, Terragrunt will automatically update the S3 resource to match the configuration specified in the remote_state bucket. For example, if you require versioning in the remote_state block, but the underlying state bucket doesnâ€™t have versioning enabled, Terragrunt will automatically turn on versioning on the bucket to match the configuration.

From https://terragrunt.gruntwork.io/docs/features/keep-your-remote-state-configuration-dry/#create-remote-state-and-locking-resources-automatically
***

**ohmer** commented *Oct 23, 2023*

I observing the same behavior with the following:

```
locals {
  git_origin_url = run_cmd("--terragrunt-quiet", "git", "config", "--get", "remote.origin.url")

  remote_state_tags = {
    ManagedBy    = "Terragrunt"
    GitOriginUrl = local.git_origin_url
  }
}

remote_state {
  backend = "s3"

  config = {
    <Truncated for clarity>
    s3_bucket_tags      = local.remote_state_tags
    dynamodb_table_tags = local.remote_state_tags
  }

  generate = {
    path      = "remote-state.tf"
    if_exists = "overwrite"
  }
}
```

I would love for Terragrunt to update the S3 and DynamoDB resource tags.
***

