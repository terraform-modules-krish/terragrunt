# What is a good size for infrastructure modules? Any best practices?

**trallnag** commented *Jan 27, 2021*

DRY code is achieved by capsuling Terraform code that is the same across environments in infrastructure modules. The `inputs` in the Terraform HCLs in the live repository only / mostly inject dependencies and values that are different from environment to environment. With this I'm following overall recommendations given in various comments, blog posts, documentation and so on. For example as a reference:

- <https://github.com/gruntwork-io/terragrunt-infrastructure-live-example/blob/master/terragrunt.hcl>
- <https://github.com/gruntwork-io/terragrunt-infrastructure-modules-example/blob/master/mysql/README.md>

What this does not answer for me is how granular single infrastructure modules (so not the generic modules like in the Terraform registry) should be. All the examples I have found were "too simple".

Let's take AWS EKS / Kubernetes as an example that I'm currently learning. It consists out of multiple components. Should I try to put everything into a single infrastructure module `eks`? In my case this is not completely possible, because I actually need at least 2 separate `apply` steps (recommended by the Terraform K8s provider).

Or rather split it all up? Here the issue is that if I split it up enough, I will end up with a bunch of rather small components with a fairly big dependency tree. At this point it starts to feel like Terragrunt simply replaces Terraforms `depends_on` just with an additional layer. Here for example:

- eks-cluster
- eks-fargate-profile
- eks-node-group-graviton
- eks-node-group-nvidia
- eks-auth
- ...

So basically with this you can map the infrastructure modules 1:1 to modules in the TF registry. In this case EKS modules by Cloudposse.

I appreciate your opinions and recommendations 
<br />
***


**yorinasub17** commented *Feb 3, 2021*

This is a good question, and is an area of active research even for Gruntwork. When it comes to componentization, the best thing that has worked for us is to base it on the reason why you want to break up your state file in the first place. In general, there are 3 key benefits to breaking up your state file:

- Performance: You keep your modules and deployments smaller, so `plan` and `apply` can run faster per iteration. You can also apply the changes across multiple workers, increasing parallelism and concurrency of deployments.
- Reliability: By isolating and componentization your changes, you run less risk of having a larger blast radius and having unintended consequences. In a world where a small typo could end up destroying things, having the ability to limit the actions is huge in keeping your infrastructure safe.
- Security: You may not want all your developers to have access to touch everything. Breaking up state files allows you to set up fine grained ACLs to split up the permissions needed to do a deployment.

On the other hand, breaking up state files adds a lot of complexity to the dependency management, and you lose the benefits of having reliable planning mechanisms. So you don't want to break it down too much.

Given that, the following litmus test has worked well for us when it comes to breaking things up:

- How long does it take to deploy your changes? A big fat terraform module might take 10-15 minutes just to run `plan`. This might be ok for something that is deployed infrequently (e.g., once per year), but could add up to a lot of wasted time if it is done multiple times per day. You may want to break that up so that you can deploy in parallel across multiple workers (since only one process can touch the state file at a time).

- How often does the infrastructure change? For example, you might deploy your application and service multiple times per day, touch your kubernetes cluster (like make node adjustments) a few times per month, and update your network architecture once per year. So it is natural to break up your components in to `application`, `eks`, and `vpc`, since the deploy frequency is very different.

- What level of granularity do you need for ACLs? For large organization, you may want only a small subset of trusted developers to access the full stack of the infrastructure. You may even have tiers, where only a handful has access to IAM, some have access to VPC and eks, but everyone has access to k8s services. Breaking up the state file and managing the ACLs via s3 bucket policies can provide this fine grained access control.
***

**trallnag** commented *Feb 3, 2021*

Thanks for the in-depth answer, it helps a lot. It's certainly necessary to find a good balance. On the other hand it can also make sense to just commit to a specific setup and follow through with it instead of trying to optimize. That goes especially for deployments with a smaller scope. Once I've collected more experience working with it, I'll try to give an update on it.
***

**yorinasub17** commented *Sep 27, 2021*

Closing this as the original question has been answered. If there are any follow ups, please open a new ticket with updated context. Thanks!
***

**josh-padnick** commented *Jul 25, 2023*

_Building on @yorinasub17's excellent response, I recently shared the following a customer:_

So, your question is an important one: Shouldn't module X expose all the variables I could ever want for my setup?

The answer is that "interface elegance" is just one factor that we need to optimize for. The other ones are performance, reusability, and reliability. In practice, we've found that building Terraform modules as small reusable building blocks leads to a better overall experience. When modules are built as small reusable building blocks, we can test them independently, and if one of the modules fails, the "blast radius" is minimized. In addition, you can deploy one part of your solution, and then incrementally add another part, leading to a smaller surface area to debug.

I've seen teams use Teraform modules that expose exactly the right knobs, yet take 15 minutes to execute a plan because they try to do too much. 

In the end, if we included every possible feature in our module, the module would be huge, take forever to run, be hard to test, and upgrades would be challenging. 

That being said, you can still expose whatever interface you want to your end users using the [wrapper module pattern](https://docs.gruntwork.io/library/usage/customizing-modules/#creating-a-wrapper-module). In the example there, the wrapper module wraps a single Gruntwork module (lambda), but you can wrap the EKS service catalog module and the autoscaler module if you'd prefer. You can then expose exactly the interface you want to end users.
***

