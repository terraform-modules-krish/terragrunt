# [Question] How to use wrapper data sources with terragrunt in live repos

**shinka81** commented *Jul 11, 2017*

Hi! I am looking for documentation or an example of how to use data sources (remote state in particular) with Terragrunt config. For example I have the following Terragrunt config and tf data source:

```
# main.tf
data "aws_availability_zones" "available" {}
```

```
# terraform.tfvars
terragrunt = {
  terraform {
    source = "git::git@github.com:some_org/some_vpc_module.git?ref=0.1.0"
  }

  # Include all settings from the root terraform.tfvars file
  include = {
    path = "${find_in_parent_folders()}"
  }
}

cidr_blocks = {
  vpc       = "10.100.9.0/24"
  public_a  = "10.100.9.0/27"
  public_b  = "10.100.9.32/27"
  general_a = "10.100.9.64/27"
  general_b = "10.100.9.96/27"
}
availability_zones = ["${data.aws_availability_zones.available.names}"]
```

When I go to plan I get `Invalid interpolation syntax. Expected syntax of the form '${function_name()}', but got '${data.aws_availability_zones.available.names}'`. Seems like the only interpolation allowed is terragrunt specific functions? In past projects we would isolate live modules per env/folder but pass in inputs/outputs using remote state data sources (i.e. passing in a security group id to whitelist to another module, subnet id, an end point to use, etc)

My question is: is this possible? If not, how do you recommend passing in dependent information from other modules in a live repo with terragrunt?

Let me know if this needs some more clarification, thanks!

<br />
***


**josh-padnick** commented *Jul 11, 2017*

The `terraform.tfvars` file is a Terraform feature that Terragrunt piggy backs on. It's not specific to Terragrunt. Unfortunately, Terraform [does not support](https://github.com/hashicorp/terraform/issues/10059) interpolation in `terraform.tfvars` files.

> My question is: is this possible? If not, how do you recommend passing in dependent information from other modules in a live repo with terragrunt?

The short answer is that, as far as I know, you can't. However, see the Terragrunt core use case [Keep Your Remote State Config Dry](https://github.com/gruntwork-io/terragrunt#keep-your-remote-state-configuration-dry) to see the technique we use at Gruntwork when setting up best-practices infrastructure for clients.
***

**brikis98** commented *Jul 12, 2017*

To add to @josh-padnick's response, the way to handle this is to use the data source in your Terraform (`.tf` files) and not in the `.tfvars` files. 
***

**shinka81** commented *Jul 17, 2017*

Thanks for the info! Closing this issue.
***

**konstantin-recurly** commented *Apr 10, 2020*

@brikis98 is there an example of the structure for this? 
I have tried this structure, doesn't seem that it works in this way
```
us-central1
├── gke
│   ├── cluster
│   │   ├── data.tf
│   │   └── terragrunt.hcl
...
```
in `data.tf` I have 
```
data "google_compute_zones" "available" {
}
```
in `terragrunt.hcl` I have 
```
inputs = {
  project_id                 = local.common.devops_project_id
  name                       = "${local.service}-gke-cluster"
  region                     = local.regional["region"]
  zones                      = ["us-east4-a", "us-east4-b"]
}
```
So as you can see I have to manually specify the zones, what I would like to be able to do is to use 
`slice(data.google_compute_zones.available.names, 0, 2)`
I have tried to create a local variable in `terragrunt.hcl` in locals like so
```
locals {
zones = slice(data.google_compute_zones.available.names, 0, 2)
}
```
here is the result of running `terragrunt plan`
```
[terragrunt] 2020/04/10 14:45:08 Not all locals could be evaluated:
[terragrunt] 2020/04/10 14:45:08 	- zones
[terragrunt] 2020/04/10 14:45:08 Could not evaluate all locals in block.
```
***

**yorinasub17** commented *Apr 10, 2020*

Terragrunt does not process terraform files inline during configuration parsing. What @brikis98 means here is to not attempt to depend on or pass in terraform data source from terragrunt as an input variable, and instead do that interpolation directly in your terraform module.

If you insist on this model where you want to dynamically look up values in your terragrunt configuration, then you will need to create a separate terraform + terragrunt module that outputs the data source information and pull that in using `dependency` blocks.
***

**konstantin-recurly** commented *Apr 10, 2020*

well, in many cases we use community modules, that don't have that in place, which means we need to fork a community module to add one data source. 

***

**yorinasub17** commented *Apr 10, 2020*

I understand the challenge, but unfortunately adding terraform level processing even just for data sources goes beyond the scope of what terragrunt is intending to accomplish (it would be more than just a wrapper). The canonical way we recommend addressing this is to treat the community modules as library modules, and create wrapper modules as the top level module that you then call using terragrunt. This gives you the flexibility to use all the powers of terraform such as data source lookups, while keeping your terragrunt config simple.

Here are also a few other alternatives:

- Create a different terraform/terragrunt module to look up that info and use [dependency blocks](https://terragrunt.gruntwork.io/docs/features/execute-terraform-commands-on-multiple-modules-at-once/#passing-outputs-between-modules)
- Use [run_cmd](https://terragrunt.gruntwork.io/docs/reference/built-in-functions/#run_cmd) to look them up using the awscli, or a custom script.

Unfortunately I don't have any examples for these and am a bit buried to generate them on the fly. The best we have is the walkthrough in [our production deployment guide](https://gruntwork.io/guides/foundations/how-to-use-gruntwork-infrastructure-as-code-library/#using_terraform_modules), although that is in the context of Gruntwork's private IaC library catalog.
***

**konstantin-recurly** commented *Apr 13, 2020*

So, I found a different way or maybe what you ment.
What I have created a new `data` folder and now I have this structure
```
 tree
.
├── data
│   ├── data.tf
│   ├── providers.tf
│   └── terragrunt.hcl
├── kms
│   ├── providers.tf
│   └── terragrunt.hcl
``` 
in the `data` folder, I have 
`data.tf` with following
```
data "google_project" "this" {
  project_id = var.project_id
}
#############
## Outputs ##
#############
output "project_number" {
  value = data.google_project.this.number
}
###############
## Variables ##
###############
variable "project_id" {
  type = string
}
```
`terragrunt.hcl` with following
```
terraform {
  source = "./"
}


locals {
  default_yaml_path = find_in_parent_folders("empty.yaml")
  common            = yamldecode(file("${get_terragrunt_dir()}/${find_in_parent_folders("common.yaml", local.default_yaml_path)}"))
  regional          = yamldecode(file("${get_terragrunt_dir()}/${find_in_parent_folders("regional.yaml", local.default_yaml_path)}"))

}


# Include all settings from the root terragrunt.hcl file
include {
  path = find_in_parent_folders()
}


inputs = {
  #This module uses the default common vars for this env/region
  #In the future we will reference states using dependencies
}
```
this is how I get all data source that I need and here is the example of how to use the data:
in the `kms` folder, I have 
`terragrunt.hcl` with the following
```
terraform {
  source = "git@github.com:terraform-google-modules/terraform-google-kms.git?ref=v1.1.0"
}

dependency "data" {
  config_path = "../data"
}

dependencies {
  paths = ["../data"]
}

locals {
  default_yaml_path = find_in_parent_folders("empty.yaml")
  common            = yamldecode(file("${get_terragrunt_dir()}/${find_in_parent_folders("common.yaml", local.default_yaml_path)}"))
  regional          = yamldecode(file("${get_terragrunt_dir()}/${find_in_parent_folders("regional.yaml", local.default_yaml_path)}"))
...

}

# Include all settings from the root terragrunt.hcl file
include {
  path = find_in_parent_folders()
}

inputs = {
  #This module uses the default common vars for this env/region
  #In the future we will reference states using dependencies
  project_id = local.common.project_id
  location   = local.regional["region"]

  keyring            = local.kms_naming
  keys               = [local.kms_naming]
  set_encrypters_for = [local.kms_naming]
  set_decrypters_for = [local.kms_naming]
  encrypters         = ["serviceAccount:service-${dependency.data.outputs.project_number}@container-engine-robot.iam.gserviceaccount.com"]
  decrypters         = ["serviceAccount:service-${dependency.data.outputs.project_number}@container-engine-robot.iam.gserviceaccount.com"]
}
```
and it works as I expected
I hope this will help someone else. 
***

**yorinasub17** commented *Apr 13, 2020*

Yup that is exactly what I meant in one of my suggestions! Thanks for sharing the example 👍 
***

**bluemalkin** commented *Dec 15, 2020*

This saved me too, thank you !
***

**queglay** commented *Jun 5, 2021*

Absolute gold here, thankyou for this example and discussion.  I've been testing this out as a new way to keep a module more loosely coupled over the last few weeks, and functionally its been very nice, Hahsicorp could take some inspiration out of what is happening here.    

One thing I haven't been able to cleanly solve is the naming conventions in the tree:

We might have one module that looks like this...
```
terraform-aws-s3-file-gateway % tree
.
├── data
│   ├── data.tf
│   ├── terragrunt.hcl
│   └── variables.tf
└── module
    ├── main.tf
    ├── outputs.tf
    ├── terragrunt.hcl
    └── variables.tf
```
...Where `module` is normally the actual git module, one level up is just implementation of that module.  This doesn't get to keep its actual module name which would normally be 'terraform-aws-s3-file-gateway'.

but if the tree instead looked like this, the structure seems a bit strange and repetitive:
```
terraform-aws-s3-file-gateway % tree
.
├── data
│   ├── data.tf
│   ├── terragrunt.hcl
│   └── variables.tf
└── terraform-aws-s3-file-gateway
    ├── main.tf
    ├── outputs.tf
    ├── terragrunt.hcl
    └── variables.tf
```

...Seems like a simple thing, but I'm sure I could do this part better somehow.
***

**dempti** commented *Mar 24, 2022*

I have a similar requirement but in my case what I want is the eks cluster detail ``` 6: data "aws_eks_cluster" "cluster" {```

So, unless applied, the terragrunt run-all plan fails all the time.
here is my data.tf

```
data "aws_eks_cluster_auth" "cluster" {
  name = var.cluster_id
}

data "aws_eks_cluster" "cluster" {
  name = var.cluster_id
}
data "aws_availability_zones" "available" {
}

#############
## Outputs ##
#############
output "aws_eks_cluster" {
  value     = data.aws_eks_cluster.cluster
  sensitive = true
}
output "aws_eks_cluster_auth" {
  value     = data.aws_eks_cluster_auth.cluster
  sensitive = true
}
output "aws_availability_zones" {
  value     = data.aws_availability_zones.available
  sensitive = true
}

###############
## Variables ##
###############
variable "cluster_id" {
  type = string
}
```

here is my terragrunt.hcl
```
terraform {
  source = "./"
}


locals {
  default_yaml_path = find_in_parent_folders("empty.yaml")
}


# Include all settings from the root terragrunt.hcl file
include {
  path = find_in_parent_folders()
}

dependency "eks" {
  config_path                             = find_in_parent_folders("/modules/eks/")
  mock_outputs_allowed_terraform_commands = ["validate", "plan", "terragrunt-info", "show"]
  mock_outputs = {
    cluster_id     = "manish-eks-test"
  }
}

generate "provider-local" {
  path      = "data.tf"
  if_exists = "overwrite_terragrunt"
  contents  = <<EOF
data "aws_eks_cluster_auth" "cluster" {
  name = var.cluster_id
}

data "aws_eks_cluster" "cluster" {
  name = var.cluster_id
}
data "aws_availability_zones" "available" {
}

#############
## Outputs ##
#############
output "aws_eks_cluster" {
  value     = data.aws_eks_cluster.cluster
  sensitive = true
}
output "aws_eks_cluster_auth" {
  value     = data.aws_eks_cluster_auth.cluster
  sensitive = true
}
output "aws_availability_zones" {
  value     = data.aws_availability_zones.available
  sensitive = true
}

###############
## Variables ##
###############
variable "cluster_id" {
  type = string
}
EOF
}

inputs = {
  cluster_id = dependency.eks.outputs.cluster_id
  #This module uses the default common vars for this env/region
  #In the future we will reference states using dependencies
}
```

This is the error I keep getting.
```
╷
│ Error: error reading EKS Cluster (test-eks-test): couldn't find resource
│
│   with data.aws_eks_cluster.cluster,
│   on data.tf line 6, in data "aws_eks_cluster" "cluster":
│    6: data "aws_eks_cluster" "cluster" {
│
╵```

***

