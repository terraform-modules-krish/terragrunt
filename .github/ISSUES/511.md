# plan-all results in connections to code commit being trottled

**Moncky** commented *Jul 5, 2018*

I think this issue is subtly different to #388

I currently have a layout that looks like:

```
.
├── _global
│   └── users
│       ├── usera
│       │   └── terraform.tfvars
│       ├── userb
│       │   └── terraform.tfvars
│       └── userc
│           └── terraform.tfvars
├── account.tfvars
├── buildspec.yml
├── eu-west-2
│   └── buildsystem
│       ├── codebuild
│       │   └── deploy_to_mgmt
│       │       └── terraform.tfvars
│       └── codecommit
│           ├── codebuild
│           │   └── terraform.tfvars
│           ├── codecommit
│           │   └── terraform.tfvars
│           ├── user
│           │   └── terraform.tfvars
│           ├── dev
│           │   └── terraform.tfvars
│           ├── devplans
│           │   └── terraform.tfvars
│           ├── mgmt
│           │   └── terraform.tfvars
│           ├── mgmtplans
│           │   └── terraform.tfvars
│           ├── prod
│           │   └── terraform.tfvars
│           ├── prodplans
│           │   └── terraform.tfvars
│           ├── spg_infra
│           │   └── terraform.tfvars
│           ├── staging
│           │   └── terraform.tfvars
│           ├── stagingplans
│           │   └── terraform.tfvars
│           ├── testing
│           │   └── terraform.tfvars
│           └── testingplans
│               └── terraform.tfvars
└── terraform.tfvars
 ```

Im just trying to get things up and running just now and if I run terraform apply-all from the root for the project I get errors like this on some of my repos, (usually only 2 or 3 but its enough to cause my builds to fail):

```
[31mError copying source module: error downloading 'ssh://git-codecommit.eu-west-2.amazonaws.com/v1/repos/codecommit': /usr/bin/git exited with 128: Cloning into '/tmp/tf139393052/module'...
Throttled: too many concurrent connections.
fatal: Could not read from remote repository.
```

Ideally I'd like to detect which of the tfvars have changed and run a plan/apply on those directories only.  My ultimate plan is to generate state files which will be committed to a different repo which will then trigger a review job for someone to then merge and run the state files.  But thats the next step. 


In the short term is there any way to reduce the rate at which terragrunt apply-all triggers the individual terraform processes?
<br />
***


**brikis98** commented *Jul 6, 2018*

Hm, I'm not sure. We've seen the throttling issue with other providers—e.g., GitHub—and it's not clear what the solution would be. The throttling limits/rules vary from provider to provider, and I'm guessing the error messages do too.

The best I can think of is to accept a `--terragrunt-concurrency` parameter that limits the max # of modules Terragrunt will `apply` or `plan` at once when you run` apply-all` or `plan-all`. 
***

**Moncky** commented *Jul 6, 2018*

I spoke to Amazon yesterday to see if I was hitting a soft limit, but their preference was to add exponential backoff.

Difficult if the providers give inconsistent error messages.

A concurrency option would be a decent solution, in my case, as its only a small set of modules that are affected and wouldn't slow down execution time that much

***

**ryno75** commented *Sep 23, 2019*

This is most definitely needed... a tunable concurrency/thread option.
***

