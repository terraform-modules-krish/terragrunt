# remote state file pass different values for different environment

**stepintooracledba** commented *May 19, 2022*

Hi Team,
I'm trying to have remote state file in my root terragrunt.hcl like this.
```
remote_state {
    backend = "s3"
    generate = {
        path = "backend.tf"
        if_exists = "overwrite_terragrunt"
    }    
    config = {
        encrypt = true
        bucket = <bucket>
        key = "terragrunt_euw1.tfstate"
        region = <region>
        profile = <profile>
        disable_bucket_update = true
    }
}
```

I have 2 environments, nonprod and prod. The bucket name and profile name will change as per the environment.

How can i pass the QA bucket name when i deploy from QA folder? Please suggest..

<br />
***


**denis256** commented *May 20, 2022*

Hi,
I was thinking about usage of [`get_env`](https://terragrunt.gruntwork.io/docs/reference/built-in-functions/#get_env) function, but it will require to define required values in environment before running terragrunt

Another approach can be done by extracting S3 config in a separated HCL file and read specific configurations through [`read_terragrunt_config`](https://terragrunt.gruntwork.io/docs/reference/built-in-functions/#read_terragrunt_config) in each included directory.

```
.
├── env1
│   ├── backend.tf
│   ├── main.tf
│   ├── s3_config.hcl
│   └── terragrunt.hcl
├── env2
│   ├── backend.tf
│   ├── main.tf
│   ├── s3_config.hcl
│   └── terragrunt.hcl
└── s3.hcl

```

```
# s3.hcl
locals {
  s3_config = read_terragrunt_config("s3_config.hcl")
}
remote_state {
  backend = "s3"
  config = {
    bucket = local.s3_config.inputs.bucket
    region = local.s3_config.inputs.region
    dynamodb_table = local.s3_config.inputs.bucket
    ...
  }
}

```

```
# env*/s3_config.hcl

inputs = {
  bucket = "bucket-env*"
  region = "region-for-env*"
}
```

Full example:

https://github.com/denis256/terragrunt-tests/tree/master/s3-bucket-multi-env

***

