# Memory usage on large object into source directory

**rlanore** commented *Jun 22, 2022*

Hi all
We have an issue with terragrunt for upload a large object with filemd5 terraform function.
When i go to .terragrunt-cache directory and terraform plan / apply no memory usage seen
With terragrunt plan/apply memory usage is equal to file size. here 5G

**Version**
$ terragrunt -version
terragrunt version v0.36.0
$ terraform -version
Terraform v1.1.7
on linux_amd64
+ provider registry.terraform.io/hashicorp/aws v4.19.0

**Code**
```
resource "aws_s3_bucket" "vm_import" {
  bucket = "${var.context}-${var.project}-vm-import-bucket"
}

resource "aws_s3_object" "object" {
    bucket = aws_s3_bucket.vm_import.id
    key    = "sample"
    source = "./vmdk_src/sample.vmdk"
    etag = filemd5("./vmdk_src/sample.vmdk")
}
```
<br />
***


**rlanore** commented *Jun 22, 2022*

Appear to not related to aws or filemd5 terraform function.
With only en empty tf file file if source of terragrunt point to directory with large file it consume memory of all file into it.
***

**denis256** commented *Jun 22, 2022*

Hi,
I think the issue is that Terragrunt checksums or copies large files to `.terragrunt-cache` directory
I can think about a couple of workarounds:
  * keep vmdk file in a separate directory, outside of terragrunt execution and pass path to files through functions like `${get_repo_root()}/vmdks/file.vmdk`
  * make move files to a hidden directory that are ignored during copy and functions like `get_terragrunt_dir / get_repo_root` to pass full path

Links: 
https://terragrunt.gruntwork.io/docs/reference/built-in-functions/#get_repo_root
https://terragrunt.gruntwork.io/docs/reference/built-in-functions/#get_terragrunt_dir
***

**rlanore** commented *Jun 22, 2022*

Thanks it's works.
***

