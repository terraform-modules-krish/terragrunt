# Can't execute plan-all because of state lock on pg backend

**andy812** commented *Feb 3, 2020*

I want to set `backend = "pg"`, but i think it's not supported.
I created the project with simple structure:
```
grunt
├── terragrunt.hcl
├── ft1
│   ├── main.tf
│   └── terragrunt.hcl
└── ft2
    ├── main.tf
    └── terragrunt.hcl
```
My root terragrunt.hcl:
```
remote_state {
  backend = "pg"
  config = {
    conn_str = "postgres://terraform:changeme@localhost/terraform?sslmode=disable"
  }
}
```
One of my main.tf:
```
terraform {
  backend "pg" {}
}

provider "aws" {
  region     = "eu-central-1"
  access_key = "XXXXXXXXXX"
  secret_key = "XXXXXXXXXX"
}

resource "aws_security_group" "allow_tls2" {
  name        = "terragrunt_2"
  description = "terragrunt_2"
  vpc_id      = "vpc-XXXXXX"

  ingress {
    from_port   = 443
    to_port     = 443
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags = {
    Name = "terragrunt_2"
  }
}
```
The second one is a similar.
I try to run terragrunt:
```
Refreshing Terraform state in-memory prior to plan...
The refreshed state will be used to calculate this plan, but will not be
persisted to local or remote state storage.
------------------------------------------------------------------------
An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # aws_security_group.allow_tls2 will be created
  + resource "aws_security_group" "allow_tls2" {
      + arn                    = (known after apply)
      + description            = "terragrunt_2"
      + egress                 = (known after apply)
      + id                     = (known after apply)
      + ingress                = [
          + {
              + cidr_blocks      = [
                  + "0.0.0.0/0",
                ]
              + description      = ""
              + from_port        = 443
              + ipv6_cidr_blocks = []
              + prefix_list_ids  = []
              + protocol         = "tcp"
              + security_groups  = []
              + self             = false
              + to_port          = 443
            },
        ]
      + name                   = "terragrunt_2"
      + owner_id               = (known after apply)
      + revoke_rules_on_delete = false
      + tags                   = {
          + "Name" = "terragrunt_2"
        }
      + vpc_id                 = "vpc-a5c023cf"
    }

Plan: 1 to add, 0 to change, 0 to destroy.

------------------------------------------------------------------------

Note: You didn't specify an "-out" parameter to save this plan, so Terraform
can't guarantee that exactly these actions will be performed if
"terraform apply" is subsequently run.

[terragrunt] [/Users/grunt/ft2] 2020/02/03 18:15:07 Module /Users/grunt/ft2 has finished successfully!
[terragrunt] 2020/02/03 18:15:07 Error with plan: [terragrunt] [/Users/grunt/ft1] 2020/02/03 18:15:03 Running command: terraform --version

**Error: Error locking state: Error acquiring the state lock: Workspace is already locked: default**
Lock Info:
  ID:        cf084f94-98c1-59b6-623b-464789b12332
  Path:      
  Operation: OperationTypePlan
  Who:       user
  Version:   0.12.20
  Created:   2020-02-03 15:15:04.175491 +0000 UTC
  Info:      


Terraform acquires a state lock to protect the state from being written
by multiple users at the same time. Please resolve the issue above and try
again. For most commands, you can disable locking with the "-lock=false"
flag, but this is not recommended.


[terragrunt] 2020/02/03 18:15:07 Error with plan: [terragrunt] [/Users/grunt/ft2] 2020/02/03 18:15:03 Running command: terraform --version
[terragrunt] 2020/02/03 18:15:07 Encountered the following errors:
Hit multiple errors:
exit status 1
```
Why terragrunt make lock? 
<br />
***


**yorinasub17** commented *Feb 3, 2020*

Terragrunt is just forwarding the backend configuration to terraform, so this is actually terraform behavior.

Specifically, the `pg` background automatically creates a lock on the database everytime it needs to access the state. This means that there is a one-to-one mapping between the database and the state file (in terragrunt's case, each folder). So you need to update your configuration so that each child terragrunt folder becomes a new database in `pg` (the last part of the `conn_str` configuration).

I am not sure what would be the best way to do this though. Your best bet is probably using some sort of regex replacing to convert `path_relative_to_include` to a valid database name.
***

**andy812** commented *Feb 4, 2020*

I tested some configurations and can make conclusion what terragrunt is not fully compatible with pg backend. 
I used different schema_name values for each subfolder and got error:
```
Initializing the backend...
The currently selected workspace (default) does not exist.
This is expected behavior when the selected workspace did not have an existing non-empty state
```

I started to use S3 backend and everything is ok.
***

**yorinasub17** commented *Feb 4, 2020*

That error message is what you get when you first initialize the PG backend. `terragrunt` is just forwarding the config to `terraform` using `-backend-config` (in the logs, you should see the exact call terragrunt is making), so all the behavior you are seeing are inherent to `terraform`, not `terragrunt`.

In any case, glad you were able to move forward with s3! Going to close this as a terraform issue, not terragrunt.
***

